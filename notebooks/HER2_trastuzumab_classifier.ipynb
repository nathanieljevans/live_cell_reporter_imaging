{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tslearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bc28ba287d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtslearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclustering\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimeSeriesKMeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKernelKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtslearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tslearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "from tslearn.clustering import TimeSeriesKMeans, KernelKMeans\n",
    "from tslearn.metrics import dtw\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler\n",
    "from tslearn.datasets import CachedDatasets\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sbn\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../data/HER2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = 'normalized' # or 'raw'\n",
    "\n",
    "series_sel = pd.read_csv('../data/HER2/H210122_SKBR3/normalized/clover_all_cell.csv').columns[1:-3]\n",
    "\n",
    "_datas = []\n",
    "for dataset in os.listdir('../data/HER2'): \n",
    "    cl_path = '../data/HER2/' + dataset + '/' + load + '/clover_all_cell.csv'\n",
    "    ms_path = '../data/HER2/' + dataset + '/' + load + '/mscarlet_all_cell.csv'\n",
    "    _clover = pd.read_csv(cl_path)\n",
    "    _mscarl = pd.read_csv(ms_path)\n",
    "    _data = _clover.merge(_mscarl, on=['track_index', 'cell__treatment'], how='inner')\n",
    "    _data = _data.assign(dataset=dataset)\n",
    "    _datas.append(_data)\n",
    "    \n",
    "data = pd.concat(_datas, axis=0)\n",
    "\n",
    "clover_sel = [f'{x}_x' for x in series_sel]\n",
    "mscarl_sel = [f'{x}_y' for x in series_sel]\n",
    "\n",
    "data = data.assign(drug = [x.split('_', maxsplit=5)[-1] for x in data.cell__treatment])\n",
    "data = data.assign(cell_line = [x.split('_', maxsplit=5)[0] for x in data.cell__treatment])\n",
    "data = data.assign(mutant = [x.split('_', maxsplit=5)[-2] for x in data.cell__treatment])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35, 5))\n",
    "plt.bar(x=data.columns, height=data.isna().sum())\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drug.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[lambda x: x.drug.isin(['untreated', '10ug_ml_trastuzumab'])]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drug.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35, 5))\n",
    "plt.bar(x=data.columns, height=data.isna().sum())\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove na\n",
    "clover_sel = np.array(clover_sel)[~data[clover_sel].isna().any()]\n",
    "mscarl_sel = np.array(mscarl_sel)[~data[mscarl_sel].isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = data[clover_sel]\n",
    "X_train = np.stack([data[clover_sel], data[mscarl_sel]], axis=2)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Make time series shorter\n",
    "X_train = TimeSeriesResampler(sz=100).fit_transform(X_train)\n",
    "sz = X_train.shape[1]\n",
    "print(X_train.shape)\n",
    "nclus = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = TimeSeriesKMeans(n_clusters=nclus, verbose=True, random_state=0, metric='euclidean', n_jobs=8)\n",
    "y_pred = km.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for yi in range(nclus):\n",
    "    plt.subplot(5, 5, yi + 1)\n",
    "    for xx in X_train[y_pred == yi][0:250]:\n",
    "        plt.plot(xx[:,0], \"r-\", alpha=.05)\n",
    "        plt.plot(xx[:,1], \"b-\", alpha=.05)\n",
    "        \n",
    "    plt.title(f'cluster sz: {len(X_train[y_pred == yi])}')\n",
    "    plt.plot(km.cluster_centers_[yi][:,0], \"r-\", label='clover')\n",
    "    plt.plot(km.cluster_centers_[yi][:,1], \"b-\", label='mscarlet')\n",
    "    \n",
    "    plt.xlim(0, sz)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n",
    "             transform=plt.gca().transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "y_trt = lb.fit_transform([f'{x}--{y}' for x,y in zip(data.cell__treatment.values, data.dataset.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_cnts = {c:np.zeros(nclus) for c in lb.classes_} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, clus, grp in zip(range(len(y_pred)), y_pred, y_trt) :\n",
    "    cm_cnts[lb.classes_[grp]][clus] += 1\n",
    "    \n",
    "cm_prob = {k:v/np.sum(v) for k,v in cm_cnts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [k for k,v in cm_prob.items()]\n",
    "cm = np.stack([v for k,v in cm_prob.items()], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(cm, rowvar=False)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "ax = sbn.clustermap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    square=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_stds = cm.std(axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(cm_stds, bins=7)\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('standard deviation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drug = dict(zip(data.drug.unique(), \"rbg\"))\n",
    "#row_colors = data.drug.map(drug)\n",
    "#g = sbn.clustermap(cm, row_colors=row_colors)\n",
    "# [x.split('--')[0].split('_')[-1] for x in lb.classes_], 'cell_line':[x.split('_')[4] for x in lb.classes_]\n",
    "\n",
    "drug = [x.split('--')[0].split('_')[-1] for x in labels]\n",
    "lut = dict(zip(set(drug), sbn.hls_palette(len(set(drug)), l=0.5, s=0.8)))\n",
    "row_colors = pd.DataFrame(drug)[0].map(lut)\n",
    "\n",
    "#Create additional row_colors here\n",
    "cell_line = [x.split('_')[4] for x in labels]\n",
    "lut2 = dict(zip(set(cell_line), sbn.hls_palette(len(set(cell_line)), l=0.5, s=0.8)))\n",
    "row_colors2 = pd.DataFrame(cell_line)[0].map(lut2)\n",
    "\n",
    "df = pd.DataFrame(index=labels, data=cm)\n",
    "sbn.clustermap(df, figsize=(12,15), row_colors=[row_colors, row_colors2]) \n",
    "\n",
    "#plt.ylabel('treatment')\n",
    "#plt.yticks(ticks=plt.yticks()[0], labels=[str(x) for x in labels])\n",
    "#plt.xlabel('cluster label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "PCs = pca.fit_transform(cm)\n",
    "\n",
    "print('explained variance ratio:', pca.explained_variance_ratio_)\n",
    "print('PC shape:', PCs.shape)\n",
    "res = pd.DataFrame({'pc1': PCs[:,0], 'pc2':PCs[:,1], 'treatment':[x.split('--')[0].split('_')[-1] for x in lb.classes_], 'cell_line':[x.split('_')[4] for x in lb.classes_]})\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,13))\n",
    "sbn.scatterplot(x='pc1', y='pc2', data=res, hue='cell_line', style='treatment', s=300)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "sbn.scatterplot(x='pc1', y='pc2', data=res[lambda x: (x.cell_line.isin(['WT', 'nd611']))], hue='cell_line', style='treatment', s=300)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ner = res[lambda x: (x.cell_line.isin(['WT', 'T798I']))]# & (x.treatment == 'neratinib')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 5* res_ner[['pc1', 'pc2']].values\n",
    "y = 1.*((res_ner.cell_line == 'WT') & (res_ner.treatment == '10ug_ml_trastuzumab')).values \\\n",
    "        + 2.* (res_ner.treatment == 'untreated').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]\n",
    "\n",
    "C = 10\n",
    "kernel = 1.0 * RBF([1.0, 1.0])  # for GPC\n",
    "\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    'L1 logistic': LogisticRegression(C=C, penalty='l1',\n",
    "                                      solver='saga',\n",
    "                                      multi_class='multinomial',\n",
    "                                      max_iter=10000),\n",
    "    'L2 logistic (Multinomial)': LogisticRegression(C=C, penalty='l2',\n",
    "                                                    solver='saga',\n",
    "                                                    multi_class='multinomial',\n",
    "                                                    max_iter=10000),\n",
    "    'L2 logistic (OvR)': LogisticRegression(C=C, penalty='l2',\n",
    "                                            solver='saga',\n",
    "                                            multi_class='ovr',\n",
    "                                            max_iter=10000),\n",
    "    'Linear SVC': SVC(kernel='linear', C=C, probability=True,\n",
    "                      random_state=0),\n",
    "    'GPC': GaussianProcessClassifier(kernel)\n",
    "}\n",
    "\n",
    "n_classifiers = len(classifiers)\n",
    "\n",
    "plt.figure(figsize=(3 * 3, n_classifiers * 3))\n",
    "plt.subplots_adjust(bottom=.2, top=.95)\n",
    "\n",
    "xx = np.linspace(-1, 1, 100)\n",
    "yy = np.linspace(-1, 1, 100).T\n",
    "xx, yy = np.meshgrid(xx, yy)\n",
    "Xfull = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "class_names = ['resistant', 'sensitive', 'untreated']\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X, y)\n",
    "\n",
    "    y_pred = classifier.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n",
    "\n",
    "    # View probabilities:\n",
    "    probas = classifier.predict_proba(Xfull)\n",
    "    n_classes = np.unique(y_pred).size\n",
    "    for k in range(n_classes):\n",
    "        plt.subplot(n_classifiers, n_classes, index * n_classes + k + 1)\n",
    "        plt.title(\"%s class\" % class_names[k])\n",
    "        if k == 0:\n",
    "            plt.ylabel(name)\n",
    "        imshow_handle = plt.imshow(probas[:, k].reshape((100, 100)),\n",
    "                                   extent=(-1, 1, -1, 1), origin='lower')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        idx = (y_pred == k)\n",
    "        if idx.any():\n",
    "            plt.scatter(X[idx, 0], X[idx, 1], marker='o', c='w', edgecolor='k')\n",
    "\n",
    "ax = plt.axes([0.15, 0.04, 0.7, 0.05])\n",
    "plt.title(\"Probability\")\n",
    "plt.colorbar(imshow_handle, cax=ax, orientation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = 5*res[['pc1', 'pc2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = classifiers['Linear SVC'].predict_proba(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "ax[0].hist(y_hat[:,0])\n",
    "ax[0].set_title('resistant')\n",
    "ax[1].hist(y_hat[:,1])\n",
    "ax[1].set_title('sensitive')\n",
    "ax[2].hist(y_hat[:,2])\n",
    "ax[2].set_title('untreated')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = pd.DataFrame({'prob_res':y_hat[:,0], 'prob_sens':y_hat[:,1], 'prob_untreat':y_hat[:,2]})\n",
    "res2 = pd.concat([res, pres], axis=1)\n",
    "res2 = res2.assign(call=[['res','sens','untreat'][np.argmax([x,y,z])] for x,y,z in zip(res2.prob_res, res2.prob_sens, res2.prob_untreat)])\n",
    "res2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.groupby(['call', 'treatment'])[['cell_line']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2[lambda x: x.prob_res > 0.6].sort_values('prob_res', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2[lambda x: x.prob_sens > 0.8].sort_values('prob_sens', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2[lambda x: x.prob_untreat > 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
